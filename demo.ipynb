{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "from scipy import stats\n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "import math \n",
    "\n",
    "import openai \n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from automated_prompt import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n",
      "100%|██████████| 30/30 [00:37<00:00,  1.26s/it]\n",
      "100%|██████████| 30/30 [00:39<00:00,  1.31s/it]\n",
      "100%|██████████| 30/30 [01:09<00:00,  2.32s/it]\n",
      "100%|██████████| 30/30 [00:35<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "prompts =  [\n",
    "    \"Answer the question based on the article. Your only choices of answers are A, B, C, D\",\n",
    "    \"asfasdssdf\", \n",
    "    \"\", \n",
    "    \"Do the following multiple choice question.\",\n",
    "    \"Choose from A, B, C, D\", \n",
    "]\n",
    "\n",
    "eval_results = []\n",
    "for prompt in prompts: \n",
    "    eval_result = eval(prompt, test_size=30)\n",
    "    eval_results.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt                                                                                               Accuracy   Loss\n",
      "Answer the question based on the article. Your only choices of answers are A, B, C, D                0.4        3.981805857507356\n",
      "asfasdssdf                                                                                           0.0        9.210340371976184\n",
      "                                                                                                     0.0        9.210340371976184\n",
      "Do the following multiple choice question.                                                           0.0        9.210340371976184\n",
      "Choose from A, B, C, D                                                                               0.06666666666666667 6.580820733815078\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Prompt':<100} {'Accuracy':<10} Loss\")\n",
    "for e in eval_results: \n",
    "    print(f\"{e['prompt']:<100} {e['accuracy']:<10} {e['avg_ce']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:37<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 ConfidenceInterval(low=0.6851671294577595, high=0.9148328705422406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"Answer the question based on the article. Your only choices of answers are A, B, C, D\"\n",
    "# Bad prompts: \n",
    "# prompt = \"Thoroughly scrutinize the information shared in the article before considering each of the options. Systematically discard the alternatives that don't resonate with the article’s critical concepts. Ensure that your responsive selection pertains solely from the set choices: A, B, C, or D – and mirrors the pivotal assertions advocated.\"\n",
    "\n",
    "# Good prompts: \n",
    "prompt = 'MODEL_PROMPT: \"Intersect the precise facts spoken about in the article and match them with the indicated alternatives. Your final response selection should only be A, B, C, or D.\"'\n",
    "# prompt = 'Intersect the precise facts spoken about in the article and match them with the indicated alternatives. Your final response selection should only be A, B, C, or D.'\n",
    "\n",
    "_eval_results = eval(prompt, test_size=50)\n",
    "\n",
    "print(_eval_results['accuracy'], _eval_results['ci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>article</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>correctness</th>\n",
       "      <th>ce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>We can know from the passage that the author w...</td>\n",
       "      <td>[doctor, model, teacher, reporter]</td>\n",
       "      <td>C</td>\n",
       "      <td>'teacher'</td>\n",
       "      <td>False</td>\n",
       "      <td>2.127420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Many graduates today turn to cosmetic surgery ...</td>\n",
       "      <td>[marry a better man/woman, become a model, get...</td>\n",
       "      <td>C</td>\n",
       "      <td>'get an advantage over others in job-hunting'</td>\n",
       "      <td>False</td>\n",
       "      <td>6.595118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>According to the passage, the author believes ...</td>\n",
       "      <td>[everyone should purchase perfection, whatever...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Which' s the best title for the passage?.</td>\n",
       "      <td>[Young Graduates Have Higher Expectations, You...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>What could be the best title for this passage?</td>\n",
       "      <td>[Death Toll Rises in an Accident in China, A C...</td>\n",
       "      <td>B</td>\n",
       "      <td>'A Coal Mine Accident in Central China'</td>\n",
       "      <td>False</td>\n",
       "      <td>14.706660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>From this passage we know that    _   .</td>\n",
       "      <td>[Of the 276 miners in the mine only 21 were de...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>According to the writer, which of the followin...</td>\n",
       "      <td>[The mine was owned by more than one company, ...</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>8.157505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>What's the main idea of the passage?</td>\n",
       "      <td>[In the process of making career decisions, pe...</td>\n",
       "      <td>B</td>\n",
       "      <td>'All the people should have a good knowledge o...</td>\n",
       "      <td>False</td>\n",
       "      <td>5.410985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>How many tips does the author give on career m...</td>\n",
       "      <td>[1., 2., 3., 4.]</td>\n",
       "      <td>D</td>\n",
       "      <td>'4.'</td>\n",
       "      <td>False</td>\n",
       "      <td>6.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Answer the question based on the article. Your...</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>It can be inferred that   _  .</td>\n",
       "      <td>[career decision is misunderstood by many peop...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>We can know from the passage that the author w...</td>\n",
       "      <td>[doctor, model, teacher, reporter]</td>\n",
       "      <td>C</td>\n",
       "      <td>'teacher'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Many graduates today turn to cosmetic surgery ...</td>\n",
       "      <td>[marry a better man/woman, become a model, get...</td>\n",
       "      <td>C</td>\n",
       "      <td>'get an advantage over others in job-hunting'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>According to the passage, the author believes ...</td>\n",
       "      <td>[everyone should purchase perfection, whatever...</td>\n",
       "      <td>D</td>\n",
       "      <td>'media are to blame for misleading young peopl...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Which' s the best title for the passage?.</td>\n",
       "      <td>[Young Graduates Have Higher Expectations, You...</td>\n",
       "      <td>B</td>\n",
       "      <td>'Young Graduates Look to Surgery for Better Jobs'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>What could be the best title for this passage?</td>\n",
       "      <td>[Death Toll Rises in an Accident in China, A C...</td>\n",
       "      <td>B</td>\n",
       "      <td>'Death Toll Rises in an Accident in China'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>From this passage we know that    _   .</td>\n",
       "      <td>[Of the 276 miners in the mine only 21 were de...</td>\n",
       "      <td>D</td>\n",
       "      <td>'Until the next morning another 5 miners were ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>According to the writer, which of the followin...</td>\n",
       "      <td>[The mine was owned by more than one company, ...</td>\n",
       "      <td>C</td>\n",
       "      <td>'There was at least one more similar accident ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>What's the main idea of the passage?</td>\n",
       "      <td>[In the process of making career decisions, pe...</td>\n",
       "      <td>B</td>\n",
       "      <td>'All the people should have a good knowledge o...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>How many tips does the author give on career m...</td>\n",
       "      <td>[1., 2., 3., 4.]</td>\n",
       "      <td>D</td>\n",
       "      <td>'4.'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>asfasdssdf</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>It can be inferred that   _  .</td>\n",
       "      <td>[career decision is misunderstood by many peop...</td>\n",
       "      <td>A</td>\n",
       "      <td>\"career decision is misunderstood by many peop...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>We can know from the passage that the author w...</td>\n",
       "      <td>[doctor, model, teacher, reporter]</td>\n",
       "      <td>C</td>\n",
       "      <td>'teacher'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Many graduates today turn to cosmetic surgery ...</td>\n",
       "      <td>[marry a better man/woman, become a model, get...</td>\n",
       "      <td>C</td>\n",
       "      <td>'get an advantage over others in job-hunting'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>According to the passage, the author believes ...</td>\n",
       "      <td>[everyone should purchase perfection, whatever...</td>\n",
       "      <td>D</td>\n",
       "      <td>'media are to blame for misleading young peopl...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Which' s the best title for the passage?.</td>\n",
       "      <td>[Young Graduates Have Higher Expectations, You...</td>\n",
       "      <td>B</td>\n",
       "      <td>'Young Graduates Look to Surgery for Better Jobs'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>What could be the best title for this passage?</td>\n",
       "      <td>[Death Toll Rises in an Accident in China, A C...</td>\n",
       "      <td>B</td>\n",
       "      <td>'A Coal Mine Accident in Central China'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>From this passage we know that    _   .</td>\n",
       "      <td>[Of the 276 miners in the mine only 21 were de...</td>\n",
       "      <td>D</td>\n",
       "      <td>'Until the next morning another 5 miners were ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>According to the writer, which of the followin...</td>\n",
       "      <td>[The mine was owned by more than one company, ...</td>\n",
       "      <td>C</td>\n",
       "      <td>'There was at least one more similar accident ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>What's the main idea of the passage?</td>\n",
       "      <td>[In the process of making career decisions, pe...</td>\n",
       "      <td>B</td>\n",
       "      <td>'All the people should have a good knowledge o...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>How many tips does the author give on career m...</td>\n",
       "      <td>[1., 2., 3., 4.]</td>\n",
       "      <td>D</td>\n",
       "      <td>'3.'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>It can be inferred that   _  .</td>\n",
       "      <td>[career decision is misunderstood by many peop...</td>\n",
       "      <td>A</td>\n",
       "      <td>\"career decision is misunderstood by many peop...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>We can know from the passage that the author w...</td>\n",
       "      <td>[doctor, model, teacher, reporter]</td>\n",
       "      <td>C</td>\n",
       "      <td>'teacher'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Many graduates today turn to cosmetic surgery ...</td>\n",
       "      <td>[marry a better man/woman, become a model, get...</td>\n",
       "      <td>C</td>\n",
       "      <td>'get an advantage over others in job-hunting'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>According to the passage, the author believes ...</td>\n",
       "      <td>[everyone should purchase perfection, whatever...</td>\n",
       "      <td>D</td>\n",
       "      <td>['media are to blame for misleading young peop...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Which' s the best title for the passage?.</td>\n",
       "      <td>[Young Graduates Have Higher Expectations, You...</td>\n",
       "      <td>B</td>\n",
       "      <td>'Young Graduates Look to Surgery for Better Jobs'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>What could be the best title for this passage?</td>\n",
       "      <td>[Death Toll Rises in an Accident in China, A C...</td>\n",
       "      <td>B</td>\n",
       "      <td>'A Coal Mine Accident in Central China'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>From this passage we know that    _   .</td>\n",
       "      <td>[Of the 276 miners in the mine only 21 were de...</td>\n",
       "      <td>D</td>\n",
       "      <td>'Until the next morning another 5 miners were ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>According to the writer, which of the followin...</td>\n",
       "      <td>[The mine was owned by more than one company, ...</td>\n",
       "      <td>C</td>\n",
       "      <td>'There was at least one more similar accident ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>What's the main idea of the passage?</td>\n",
       "      <td>[In the process of making career decisions, pe...</td>\n",
       "      <td>B</td>\n",
       "      <td>'All the people should have a good knowledge o...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>How many tips does the author give on career m...</td>\n",
       "      <td>[1., 2., 3., 4.]</td>\n",
       "      <td>D</td>\n",
       "      <td>'4.'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Do the following multiple choice question.</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>It can be inferred that   _  .</td>\n",
       "      <td>[career decision is misunderstood by many peop...</td>\n",
       "      <td>A</td>\n",
       "      <td>\"career decision is misunderstood by many peop...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>We can know from the passage that the author w...</td>\n",
       "      <td>[doctor, model, teacher, reporter]</td>\n",
       "      <td>C</td>\n",
       "      <td>'teacher'</td>\n",
       "      <td>False</td>\n",
       "      <td>8.531452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Many graduates today turn to cosmetic surgery ...</td>\n",
       "      <td>[marry a better man/woman, become a model, get...</td>\n",
       "      <td>C</td>\n",
       "      <td>'get an advantage over others in job-hunting'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.468829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>According to the passage, the author believes ...</td>\n",
       "      <td>[everyone should purchase perfection, whatever...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>Which' s the best title for the passage?.</td>\n",
       "      <td>[Young Graduates Have Higher Expectations, You...</td>\n",
       "      <td>B</td>\n",
       "      <td>'Young Graduates Look to Surgery for Better Jobs'</td>\n",
       "      <td>False</td>\n",
       "      <td>2.550065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>What could be the best title for this passage?</td>\n",
       "      <td>[Death Toll Rises in an Accident in China, A C...</td>\n",
       "      <td>B</td>\n",
       "      <td>'A Coal Mine Accident in Central China'</td>\n",
       "      <td>False</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>From this passage we know that    _   .</td>\n",
       "      <td>[Of the 276 miners in the mine only 21 were de...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>0.223918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>According to the writer, which of the followin...</td>\n",
       "      <td>[The mine was owned by more than one company, ...</td>\n",
       "      <td>C</td>\n",
       "      <td>'There was at least one more similar accident ...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.623773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>What's the main idea of the passage?</td>\n",
       "      <td>[In the process of making career decisions, pe...</td>\n",
       "      <td>B</td>\n",
       "      <td>'All the people should have a good knowledge o...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.913690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>How many tips does the author give on career m...</td>\n",
       "      <td>[1., 2., 3., 4.]</td>\n",
       "      <td>D</td>\n",
       "      <td>'4.'</td>\n",
       "      <td>False</td>\n",
       "      <td>6.052500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Choose from A, B, C, D</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>It can be inferred that   _  .</td>\n",
       "      <td>[career decision is misunderstood by many peop...</td>\n",
       "      <td>A</td>\n",
       "      <td>\"career decision is misunderstood by many peop...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.266505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   Answer the question based on the article. Your...   \n",
       "1   Answer the question based on the article. Your...   \n",
       "2   Answer the question based on the article. Your...   \n",
       "3   Answer the question based on the article. Your...   \n",
       "4   Answer the question based on the article. Your...   \n",
       "5   Answer the question based on the article. Your...   \n",
       "6   Answer the question based on the article. Your...   \n",
       "7   Answer the question based on the article. Your...   \n",
       "8   Answer the question based on the article. Your...   \n",
       "9   Answer the question based on the article. Your...   \n",
       "10                                         asfasdssdf   \n",
       "11                                         asfasdssdf   \n",
       "12                                         asfasdssdf   \n",
       "13                                         asfasdssdf   \n",
       "14                                         asfasdssdf   \n",
       "15                                         asfasdssdf   \n",
       "16                                         asfasdssdf   \n",
       "17                                         asfasdssdf   \n",
       "18                                         asfasdssdf   \n",
       "19                                         asfasdssdf   \n",
       "20                                                      \n",
       "21                                                      \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                                      \n",
       "25                                                      \n",
       "26                                                      \n",
       "27                                                      \n",
       "28                                                      \n",
       "29                                                      \n",
       "30         Do the following multiple choice question.   \n",
       "31         Do the following multiple choice question.   \n",
       "32         Do the following multiple choice question.   \n",
       "33         Do the following multiple choice question.   \n",
       "34         Do the following multiple choice question.   \n",
       "35         Do the following multiple choice question.   \n",
       "36         Do the following multiple choice question.   \n",
       "37         Do the following multiple choice question.   \n",
       "38         Do the following multiple choice question.   \n",
       "39         Do the following multiple choice question.   \n",
       "40                             Choose from A, B, C, D   \n",
       "41                             Choose from A, B, C, D   \n",
       "42                             Choose from A, B, C, D   \n",
       "43                             Choose from A, B, C, D   \n",
       "44                             Choose from A, B, C, D   \n",
       "45                             Choose from A, B, C, D   \n",
       "46                             Choose from A, B, C, D   \n",
       "47                             Choose from A, B, C, D   \n",
       "48                             Choose from A, B, C, D   \n",
       "49                             Choose from A, B, C, D   \n",
       "\n",
       "                                              article  \\\n",
       "0   Last week I talked with some of my students ab...   \n",
       "1   Last week I talked with some of my students ab...   \n",
       "2   Last week I talked with some of my students ab...   \n",
       "3   Last week I talked with some of my students ab...   \n",
       "4   YUZHOU, HENAN -An accident in a central China ...   \n",
       "5   YUZHOU, HENAN -An accident in a central China ...   \n",
       "6   YUZHOU, HENAN -An accident in a central China ...   \n",
       "7   Understanding the process of making career cho...   \n",
       "8   Understanding the process of making career cho...   \n",
       "9   Understanding the process of making career cho...   \n",
       "10  Last week I talked with some of my students ab...   \n",
       "11  Last week I talked with some of my students ab...   \n",
       "12  Last week I talked with some of my students ab...   \n",
       "13  Last week I talked with some of my students ab...   \n",
       "14  YUZHOU, HENAN -An accident in a central China ...   \n",
       "15  YUZHOU, HENAN -An accident in a central China ...   \n",
       "16  YUZHOU, HENAN -An accident in a central China ...   \n",
       "17  Understanding the process of making career cho...   \n",
       "18  Understanding the process of making career cho...   \n",
       "19  Understanding the process of making career cho...   \n",
       "20  Last week I talked with some of my students ab...   \n",
       "21  Last week I talked with some of my students ab...   \n",
       "22  Last week I talked with some of my students ab...   \n",
       "23  Last week I talked with some of my students ab...   \n",
       "24  YUZHOU, HENAN -An accident in a central China ...   \n",
       "25  YUZHOU, HENAN -An accident in a central China ...   \n",
       "26  YUZHOU, HENAN -An accident in a central China ...   \n",
       "27  Understanding the process of making career cho...   \n",
       "28  Understanding the process of making career cho...   \n",
       "29  Understanding the process of making career cho...   \n",
       "30  Last week I talked with some of my students ab...   \n",
       "31  Last week I talked with some of my students ab...   \n",
       "32  Last week I talked with some of my students ab...   \n",
       "33  Last week I talked with some of my students ab...   \n",
       "34  YUZHOU, HENAN -An accident in a central China ...   \n",
       "35  YUZHOU, HENAN -An accident in a central China ...   \n",
       "36  YUZHOU, HENAN -An accident in a central China ...   \n",
       "37  Understanding the process of making career cho...   \n",
       "38  Understanding the process of making career cho...   \n",
       "39  Understanding the process of making career cho...   \n",
       "40  Last week I talked with some of my students ab...   \n",
       "41  Last week I talked with some of my students ab...   \n",
       "42  Last week I talked with some of my students ab...   \n",
       "43  Last week I talked with some of my students ab...   \n",
       "44  YUZHOU, HENAN -An accident in a central China ...   \n",
       "45  YUZHOU, HENAN -An accident in a central China ...   \n",
       "46  YUZHOU, HENAN -An accident in a central China ...   \n",
       "47  Understanding the process of making career cho...   \n",
       "48  Understanding the process of making career cho...   \n",
       "49  Understanding the process of making career cho...   \n",
       "\n",
       "                                             question  \\\n",
       "0   We can know from the passage that the author w...   \n",
       "1   Many graduates today turn to cosmetic surgery ...   \n",
       "2   According to the passage, the author believes ...   \n",
       "3           Which' s the best title for the passage?.   \n",
       "4      What could be the best title for this passage?   \n",
       "5             From this passage we know that    _   .   \n",
       "6   According to the writer, which of the followin...   \n",
       "7                What's the main idea of the passage?   \n",
       "8   How many tips does the author give on career m...   \n",
       "9                      It can be inferred that   _  .   \n",
       "10  We can know from the passage that the author w...   \n",
       "11  Many graduates today turn to cosmetic surgery ...   \n",
       "12  According to the passage, the author believes ...   \n",
       "13          Which' s the best title for the passage?.   \n",
       "14     What could be the best title for this passage?   \n",
       "15            From this passage we know that    _   .   \n",
       "16  According to the writer, which of the followin...   \n",
       "17               What's the main idea of the passage?   \n",
       "18  How many tips does the author give on career m...   \n",
       "19                     It can be inferred that   _  .   \n",
       "20  We can know from the passage that the author w...   \n",
       "21  Many graduates today turn to cosmetic surgery ...   \n",
       "22  According to the passage, the author believes ...   \n",
       "23          Which' s the best title for the passage?.   \n",
       "24     What could be the best title for this passage?   \n",
       "25            From this passage we know that    _   .   \n",
       "26  According to the writer, which of the followin...   \n",
       "27               What's the main idea of the passage?   \n",
       "28  How many tips does the author give on career m...   \n",
       "29                     It can be inferred that   _  .   \n",
       "30  We can know from the passage that the author w...   \n",
       "31  Many graduates today turn to cosmetic surgery ...   \n",
       "32  According to the passage, the author believes ...   \n",
       "33          Which' s the best title for the passage?.   \n",
       "34     What could be the best title for this passage?   \n",
       "35            From this passage we know that    _   .   \n",
       "36  According to the writer, which of the followin...   \n",
       "37               What's the main idea of the passage?   \n",
       "38  How many tips does the author give on career m...   \n",
       "39                     It can be inferred that   _  .   \n",
       "40  We can know from the passage that the author w...   \n",
       "41  Many graduates today turn to cosmetic surgery ...   \n",
       "42  According to the passage, the author believes ...   \n",
       "43          Which' s the best title for the passage?.   \n",
       "44     What could be the best title for this passage?   \n",
       "45            From this passage we know that    _   .   \n",
       "46  According to the writer, which of the followin...   \n",
       "47               What's the main idea of the passage?   \n",
       "48  How many tips does the author give on career m...   \n",
       "49                     It can be inferred that   _  .   \n",
       "\n",
       "                                              options correct_answer  \\\n",
       "0                  [doctor, model, teacher, reporter]              C   \n",
       "1   [marry a better man/woman, become a model, get...              C   \n",
       "2   [everyone should purchase perfection, whatever...              D   \n",
       "3   [Young Graduates Have Higher Expectations, You...              B   \n",
       "4   [Death Toll Rises in an Accident in China, A C...              B   \n",
       "5   [Of the 276 miners in the mine only 21 were de...              D   \n",
       "6   [The mine was owned by more than one company, ...              C   \n",
       "7   [In the process of making career decisions, pe...              B   \n",
       "8                                    [1., 2., 3., 4.]              D   \n",
       "9   [career decision is misunderstood by many peop...              A   \n",
       "10                 [doctor, model, teacher, reporter]              C   \n",
       "11  [marry a better man/woman, become a model, get...              C   \n",
       "12  [everyone should purchase perfection, whatever...              D   \n",
       "13  [Young Graduates Have Higher Expectations, You...              B   \n",
       "14  [Death Toll Rises in an Accident in China, A C...              B   \n",
       "15  [Of the 276 miners in the mine only 21 were de...              D   \n",
       "16  [The mine was owned by more than one company, ...              C   \n",
       "17  [In the process of making career decisions, pe...              B   \n",
       "18                                   [1., 2., 3., 4.]              D   \n",
       "19  [career decision is misunderstood by many peop...              A   \n",
       "20                 [doctor, model, teacher, reporter]              C   \n",
       "21  [marry a better man/woman, become a model, get...              C   \n",
       "22  [everyone should purchase perfection, whatever...              D   \n",
       "23  [Young Graduates Have Higher Expectations, You...              B   \n",
       "24  [Death Toll Rises in an Accident in China, A C...              B   \n",
       "25  [Of the 276 miners in the mine only 21 were de...              D   \n",
       "26  [The mine was owned by more than one company, ...              C   \n",
       "27  [In the process of making career decisions, pe...              B   \n",
       "28                                   [1., 2., 3., 4.]              D   \n",
       "29  [career decision is misunderstood by many peop...              A   \n",
       "30                 [doctor, model, teacher, reporter]              C   \n",
       "31  [marry a better man/woman, become a model, get...              C   \n",
       "32  [everyone should purchase perfection, whatever...              D   \n",
       "33  [Young Graduates Have Higher Expectations, You...              B   \n",
       "34  [Death Toll Rises in an Accident in China, A C...              B   \n",
       "35  [Of the 276 miners in the mine only 21 were de...              D   \n",
       "36  [The mine was owned by more than one company, ...              C   \n",
       "37  [In the process of making career decisions, pe...              B   \n",
       "38                                   [1., 2., 3., 4.]              D   \n",
       "39  [career decision is misunderstood by many peop...              A   \n",
       "40                 [doctor, model, teacher, reporter]              C   \n",
       "41  [marry a better man/woman, become a model, get...              C   \n",
       "42  [everyone should purchase perfection, whatever...              D   \n",
       "43  [Young Graduates Have Higher Expectations, You...              B   \n",
       "44  [Death Toll Rises in an Accident in China, A C...              B   \n",
       "45  [Of the 276 miners in the mine only 21 were de...              D   \n",
       "46  [The mine was owned by more than one company, ...              C   \n",
       "47  [In the process of making career decisions, pe...              B   \n",
       "48                                   [1., 2., 3., 4.]              D   \n",
       "49  [career decision is misunderstood by many peop...              A   \n",
       "\n",
       "                                         model_answer  correctness         ce  \n",
       "0                                           'teacher'        False   2.127420  \n",
       "1       'get an advantage over others in job-hunting'        False   6.595118  \n",
       "2                                                   D         True   0.000375  \n",
       "3                                                   B         True   0.061969  \n",
       "4             'A Coal Mine Accident in Central China'        False  14.706660  \n",
       "5                                                   D         True   0.001213  \n",
       "6                                                   B        False   8.157505  \n",
       "7   'All the people should have a good knowledge o...        False   5.410985  \n",
       "8                                                '4.'        False   6.090130  \n",
       "9                                                   A         True   0.000751  \n",
       "10                                          'teacher'        False   9.210340  \n",
       "11      'get an advantage over others in job-hunting'        False   9.210340  \n",
       "12  'media are to blame for misleading young peopl...        False   9.210340  \n",
       "13  'Young Graduates Look to Surgery for Better Jobs'        False   9.210340  \n",
       "14         'Death Toll Rises in an Accident in China'        False   9.210340  \n",
       "15  'Until the next morning another 5 miners were ...        False   9.210340  \n",
       "16  'There was at least one more similar accident ...        False   9.210340  \n",
       "17  'All the people should have a good knowledge o...        False   9.210340  \n",
       "18                                               '4.'        False   9.210340  \n",
       "19  \"career decision is misunderstood by many peop...        False   9.210340  \n",
       "20                                          'teacher'        False   9.210340  \n",
       "21      'get an advantage over others in job-hunting'        False   9.210340  \n",
       "22  'media are to blame for misleading young peopl...        False   9.210340  \n",
       "23  'Young Graduates Look to Surgery for Better Jobs'        False   9.210340  \n",
       "24            'A Coal Mine Accident in Central China'        False   9.210340  \n",
       "25  'Until the next morning another 5 miners were ...        False   9.210340  \n",
       "26  'There was at least one more similar accident ...        False   9.210340  \n",
       "27  'All the people should have a good knowledge o...        False   9.210340  \n",
       "28                                               '3.'        False   9.210340  \n",
       "29  \"career decision is misunderstood by many peop...        False   9.210340  \n",
       "30                                          'teacher'        False   9.210340  \n",
       "31      'get an advantage over others in job-hunting'        False   9.210340  \n",
       "32  ['media are to blame for misleading young peop...        False   9.210340  \n",
       "33  'Young Graduates Look to Surgery for Better Jobs'        False   9.210340  \n",
       "34            'A Coal Mine Accident in Central China'        False   9.210340  \n",
       "35  'Until the next morning another 5 miners were ...        False   9.210340  \n",
       "36  'There was at least one more similar accident ...        False   9.210340  \n",
       "37  'All the people should have a good knowledge o...        False   9.210340  \n",
       "38                                               '4.'        False   9.210340  \n",
       "39  \"career decision is misunderstood by many peop...        False   9.210340  \n",
       "40                                          'teacher'        False   8.531452  \n",
       "41      'get an advantage over others in job-hunting'        False   9.468829  \n",
       "42                                                  D         True   0.005174  \n",
       "43  'Young Graduates Look to Surgery for Better Jobs'        False   2.550065  \n",
       "44            'A Coal Mine Accident in Central China'        False   9.210340  \n",
       "45                                                  D         True   0.223918  \n",
       "46  'There was at least one more similar accident ...        False   4.623773  \n",
       "47  'All the people should have a good knowledge o...        False   4.913690  \n",
       "48                                               '4.'        False   6.052500  \n",
       "49  \"career decision is misunderstood by many peop...        False   4.266505  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(eval_results, dict): \n",
    "    results_df = eval_results['results_df']\n",
    "elif isinstance(eval_results, list): \n",
    "    results_df = pd.concat([e['results_df'] for e in eval_results], ignore_index=True)\n",
    "else:\n",
    "    raise TypeError('error')\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Based on the context provided, select the most appropriate answer. The possible choices are A, B, C, or D.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:31<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.36666666666666664, CI=(0.18364817667544803, 0.5496851566578853), loss=3.1096224930558725\n",
      "Epoch 1\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Reflecting on the information given, identify the correct answer. The options are A, B, C, or D. Make sure to choose one.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:31<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.43333333333333335, CI=(0.24513405158484583, 0.6215326150818209), loss=2.3651271781095398\n",
      "Epoch 2\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Given the outline of the scenario and the specifics discussed, pinpoint the correct answer from the choices provided, which are A, B, C, or D. The suitable response will be in the form of the letter corresponding to the correct answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8333333333333334, CI=(0.6917941024649974, 0.9748725642016693), loss=1.0412041664229283\n",
      "Epoch 3\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Detailed in the scenario are four possible answers, A, B, C, or D. Decipher which choice is most applicable based on the given context and information.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:32<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.03333333333333333, CI=(-0.03484098807109009, 0.10150765473775675), loss=7.4788033171976185\n",
      "Epoch 4\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Consider the presented information and data. Your task is to choose the most fitting answer among possible choices, labeled as A, B, C, or D.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:31<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.23333333333333334, CI=(0.0727003361293263, 0.39396633053734037), loss=1.9304970338825398\n",
      "Epoch 5\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Based on the given context and the information discussed, determine the accurate response among the options provided - A, B, C, or D. Only a single letter corresponding to the correct answer must be the proper output.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.7666666666666667, CI=(0.6060336694626596, 0.9272996638706739), loss=1.96170014916017\n",
      "Epoch 6\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Analyzing the scenario and the elements discussed, identify the most suited reply from the choices given, which include A, B, C, or D. The proper response should be in the form of the letter linked with the correct answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8666666666666667, CI=(0.7375630244878586, 0.9957703088454748), loss=1.3797429729712034\n",
      "Epoch 7\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Reflecting on all the facts and details stated in the article, what is the best response? Remember to select only one correct lettered choice from the options A, B, C, or D.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:26<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.3333333333333333, CI=(0.15429879420839188, 0.5123678724582748), loss=2.3365871382744667\n",
      "Epoch 8\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Refer to the given details and discussion and discern the correct response from the options A, B, C, or D. Deliver your response as the single most fitting letter.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=1.2279440830843882\n",
      "Epoch 9\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Instructions: Based on the content and data provided, narrow down to the most precise response among options - A, B, C, or D. Your reaction should be simply in terms of the letter that fully justifies the correct answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9333333333333333, CI=(0.8385971600102016, 1.0280695066564651), loss=1.0866600620198434\n",
      "Epoch 10\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Consider the details provided in the context. Select the best answer from A, B, C, and D. Please express your answer only through the relevant letter.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=1.110453936945521\n",
      "Epoch 11\n",
      "### Generating a new prompt ###\n",
      "Limit reached at epoch Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8615 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Restarting message.\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Reflect upon the provided materials. Choose the correct solution among A, B, C, or D - please communicate your answer as the single corresponding letter that best illustrates the correct response.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8333333333333334, CI=(0.6917941024649974, 0.9748725642016693), loss=1.4849867841872308\n",
      "Epoch 12\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Prompt: MODEL_PROMPT: Assess the provided information and content. Decide the right answer from the options A, B, C, or D. Please formulate your answer as the corresponding letter that accurately indicates the correct answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.7666666666666667, CI=(0.6060336694626596, 0.9272996638706739), loss=1.2629904136467294\n",
      "Epoch 13\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Given the context and details, deduce the most accurate answer among the provided options - A, B, C, or D. Ensure that your response consists merely of the single letter that corresponds to the correct answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=1.0844321748453205\n",
      "Epoch 14\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Given the information, evaluate and identify the accurate answer from the options: A, B, C, or D. Remember, your answer should leverage the singular letter corresponding to the right option.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8, CI=(0.6480841559817748, 0.9519158440182253), loss=1.53484686647723\n",
      "Epoch 15\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Observe the presented context carefully. Determine the best selection from given options - A, B, C, or D. Your answer should only comprise the letter synonymous with the correct solution.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: 19.649947\n",
      "\n",
      "Prompt: MODEL_PROMPT: Given the data and context, deduct the most accurate answer among the scope of options - A, B, C, or D. Hieroglyph your response in only the letter that relates to the precise reply.\n",
      "Correct Answer: A\n",
      "Model Answer: C\n",
      "Entropy: 19.078424\n",
      " \n",
      "Prompt: MODEL_PROMPT: Guide: Processing the given background and related information, cull the accurate answer from options, namely A, B, C, or D. Use only the letter connoting the correct response as your determined output.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 18.49544\n",
      " \n",
      "Prompt: MODEL_PROMPT: Using the context and facts, infer the ideal counter from the four alternatives - A, B, C, or D. Stick with only the corresponding letter for the appropriate answer as your final input.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Do examine scrutinizing all the given context and make a dissection to draw the correct response among A, B, C, or D options. Keep your output entail only with the apt letter represents the resolved answer.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Guidelines: After scrutinizing the furnished details, identify the precise answer from - A, B, C, or D. Your conclusion should exist purely as the single representation matching with the resolved answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Reminders: Upon a detailed examination of the consolidated data on premise, home in on the strict response among the options - A, B, C, or D. Recollect that your designated settlement should be simply composed of the letter compatible with the correct answer.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:54<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 16\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "\n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Refer to the given details and discussion and discern the correct response from the options A, B, C, or D. Deliver your response as the single most fitting letter.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 19.49444\n",
      " \n",
      "Prompt: MODEL_PROMPT: Based on the given context and the information discussed, determine the accurate response among the options provided - A, B, C, or D. Only a single letter corresponding to the correct answer must be the proper output.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 19.22336\n",
      " \n",
      "Prompt: MODEL_PROMPT: Given the outline of the scenario and the specifics discussed, pinpoint the correct answer from the choices provided, which are A, B, C, or D. The suitable response will be in the form of the letter corresponding to the correct answer.\n",
      "Correct Answer: A\n",
      "Model Answer: D\n",
      "Entropy: 19.081827\n",
      " \n",
      "Prompt: MODEL_PROMPT: Consult the provided context and details. Extract the most congruous answer out of the mentioned options - A, B, C, or D. Your output is to be the single letter that correlates to the rightful answer.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 18.628446\n",
      " \n",
      "Prompt: MODEL_PROMPT: Instructions: Based on the content and data provided, narrow down to the most precise response among options - A, B, C, or D. Your reaction should be simply in terms of the letter that fully justifies the correct answer.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: 1.7678354e-07\n",
      " \n",
      "Prompt: MODEL_PROMPT: Analysing the provided context and theme, determine the suitable answer from among the choies - A, B, C, or D. Do ensure your valid response is confined only to a single, apt letter.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Consult the details in context. Select the most appropriate answer from among A, B, C, and D. Express your answer as the specific letter corresponding to the rightful response.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: In light of the provided data and information, ascertain the valid answer from the options A, B, C, or D. Your response should ideally be reduced to symbolize the A, B, C or D's representative letter.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Analyzing the scenario and the elements discussed, identify the most suited reply from the choices given, which include A, B, C, or D. The proper response should be in the form of the letter linked with the correct answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:46<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 17\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Refer to the given details and discussion and discern the correct response from the options A, B, C, or D. Deliver your response as the single most fitting letter.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 19.49444\n",
      " \n",
      "Prompt: MODEL_PROMPT: Based on the given context and the information discussed, determine the accurate response among the options provided - A, B, C, or D. Only a single letter corresponding to the correct answer must be the proper output.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 19.23336\n",
      " \n",
      "Prompt: MODEL_PROMPT: Given the outline of the scenario and the specifics discussed, pinpoint the correct answer from the choices provided, which are A, B, C, or D. The suitable response will be in the form of the letter corresponding to the correct answer.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 19.21876\n",
      " \n",
      "Prompt: MODEL_PROMPT: Instructions: Based on the content and data provided, narrow down to the most precise response among options - A, B, C, or D. Your reaction should be simply in terms of the letter that fully justifies the correct answer.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 18.906576\n",
      " \n",
      "Prompt: MODEL_PROMPT: Consider the details provided in the context. Select the best answer from A, B, C, and D. Please express your answer only through the relevant letter.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 18.656597\n",
      " \n",
      "Prompt: MODEL_PROMPT: Analysis guidance: By evaluating the content and provided information, you should synthesize the chosen response in the form of the respective single letter - A, B, C, or D - to correspond to the correct response; highlighted among the options outlined.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: 1.9361265e-07\n",
      " \n",
      "Prompt: MODEL_PROMPT: In light of the content and information at your disposal, ascertain the most valid answer among the choices - A, B, C, or D. Remember, your succinct response should be consistent with the single letter that matches the correct decision.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy:  1.9361265e-07\n",
      " \n",
      "Prompt: MODEL_PROMPT: Analyzing the scenario and information examined, specify the best fitting answer among the allotments provided as A, B, C, or D. For succinct communication, we request your reply to accurately conform to the letter which equalizes the correct answer.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Based on the circumstances and matters detailed, organize your choice that is harmonious with the options - A, B, C, or D, we advise that your appraisal should relay the exact letter that defines the correct answer.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Analysis guidance: By evaluating the content and provided information, you should synthesize the chosen response in the form of the respective single letter - A, B, C, or D - to correspond to the correct response; highlighted among the options outlined.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:18<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 18\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Reflect upon the contextual information and the details discussed. Choose the right option from A, B, C, or D that best aligns with the correct solution. Please denote your answer by expressing the single corresponding letter only.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.7666666666666667, CI=(0.6060336694626596, 0.9272996638706739), loss=1.48928795163743\n",
      "Epoch 19\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "\n",
      "The instructions below guide you to formulate a prompt. Do not include specific test questions, articles in magazines, or test answers when creating your MODEL_PROMPT. \n",
      "\n",
      "Remember, the output of this model will be used to assess it, so the more clear, concise and efficient your instruction, the better it will perform:\n",
      "\n",
      "Refer to these examples:\n",
      "\n",
      "Prompt:MODEL_PROMPT: Given the substance of information provided, predict the accurate answer marked as A, B, C or D. Bear in mind, the solution formulated must be strictly the single letter representing the right response.\n",
      "Correct Answer: B\n",
      "Model Answer: A\n",
      "Entropy : 17.935453 \n",
      "\n",
      "Prompt: MODEL_PROMPT: Read through the context thoroughly, decide on the factual answer from the selections: A, B, C or D. Your submission is expected to be merely the singular letter symbolizing the correct response.\n",
      "Correct Answer: D\n",
      "Model Answer: C\n",
      "Entropy : 19.842240 \n",
      "\n",
      "Prompt: MODEL_PROMPT: Extract the artificial intelligence sifted response from sphere of options - A, B, C, or D, given the contours of guiding parameters. Your comeback must precisely exhibit only the letter that harnesses the correct resolution.\n",
      "Correct Answer: A\n",
      "Model Answer: B\n",
      "Entropy: 22.253700 \n",
      "\n",
      "Prompt: MODEL_PROMPT: Predicated on  details and context furnished, rifle through the answer choices and identify the accurate choice from A, B, C, or D. Your retort should echo simply the single letter that epitomizes the biologically plausible answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: 0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Dovetailed to the individual elements and the overall contextual architecture, point out the accurate answer from A, B, C or D. Your response must be chrystallized in terms of the alphabet that pair correctly.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: 0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Bearing in mind the rhetorical ballpark and the discreet semiotics analyzed, churn out your best take melding A, B, C, or D options simplified to the single alphabet exhibiting key characteristics constituting the correct deduction. Please remember that your interjection must orbit the specific answer letter only.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: 0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:03<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.397603359576976\n",
      "Epoch 20\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Given the situation and specifics, infer the correct reply from the available options - A, B, C, or D. Please submit your answer only in terms of the single letter that points out the most accurate solution.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:16<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8666666666666667, CI=(0.7375630244878586, 0.9957703088454748), loss=1.4272119328507216\n",
      "Epoch 21\n",
      "### Generating a new prompt ###\n",
      "Limit reached at epoch Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8468 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Restarting message.\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Reflect, comprehend, and sort the proposed evidence. Pick out the correct solution from A, B, C, or D. Release your evaluation by using just the solitary letter that encompasses the position of the correct alternative.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=0.9742224425154029\n",
      "Epoch 22\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Prompt: MODEL_PROMPT: Using the given details, apply your comprehension in deriving the most exact solution amongst the alternatives - A, B, C, or D. For your response, purely utilize the backwards equivalent of the correct answer's index into the English alphabet.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:41<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.03333333333333333, CI=(-0.03484098807109009, 0.10150765473775675), loss=7.1138663581317445\n",
      "Epoch 23\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Having thoroughly scrutinized the information and specifics provided, derive the correct response from the alternatives given - A, B, C, or D. The appropriate reaction should be submitted strictly using the singular letter affiliated with the accurate answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=0.9475362454887267\n",
      "Epoch 24\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Upon analyzing the given information, identify the most accurate answer from the options - A, B, C, or D. Your response should simply consist of the solitary letter that denotes the correct response.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=1.2348445073338086\n",
      "Epoch 25\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model in a question-answering task. \n",
      "\n",
      "Aptly consider the content and background given to you. Choose the right option from A, B, C or D. Your response should only comprise the singular letter that aligns with the correct answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:25<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.7333333333333333, CI=(0.5653840485604633, 0.9012826181062032), loss=2.0455541928749033\n",
      "Epoch 26\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Examine the details given and decide on the most substantial reply among the alternatives given, namely A, B, C, or D. Your proper responses should be formed of only the relevant letter linked with the accurate answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8333333333333334, CI=(0.6917941024649974, 0.9748725642016693), loss=0.9754302524034778\n",
      "Epoch 27\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Applying the information shared and detailed context, evaluate and determine the most suitable answer amongst the options - A, B, C, or D. The answer should only consist of the single matching letter that respectfully echoes the proper choice.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.7666666666666667, CI=(0.6060336694626596, 0.9272996638706739), loss=2.2221266587964146\n",
      "Epoch 28\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Utilize your analysis of the shared material. Ascertain the most realizable solution mentioned in the possibilities - A, B, C or D. Then, present your conclusion by replying with the singular letter reflecting the best-suited answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8333333333333334, CI=(0.6917941024649974, 0.9748725642016693), loss=1.2120834977888266\n",
      "Epoch 29\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Evaluate the given context and data, and extract the most valid response amid the options provided - A, B, C, or D. Your output should solely consist of a solitary letter which directly corresponds to the perfect response.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Meanwhile processing the presented information, recognize the apt choice among the provided alternatives - A, B, C, or D. The response should be rendered in terms of a solitary letter associated with the precise response.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Analyzing the circumstances and content at hand, clarify the right answer from the options available, encompassing A, B, C, or D. Your given answer should robustly take into account the independent letter representing the proper response.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: With a keen eye over the given unprompted statements and background information, specify an answer from one of these options, A, B, C or D. Your chosen reply should be just the warranted letter matching the correct reply.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Contemplate the supplied context and discrete items discussed to distinguish the right reply from the choices listed - A, B, C, or D. Your appropriate response should be termed by a single alphabet representing the correct answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Upon in-depth evaluation of the provided information, determine an accurate choice from A, B, C, or D. Respond using a single letter that aligns precisely with the optimal answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Take a closer look at the context and details mentioned, and decide on the most appropriate reply from the proposed solutions - A, B, C, or D. The answer should reflect only one solitary initial that corresponds to the right decision.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Given the related particulars and narrative, deduce the favourite answer among the choices provided - A, B, C, or D. Make sure your response conveys just a single character that resonates with the correct answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: According to the involved context and specific data considered, extract rightful response among the provisions stated - A, B, C, or D. Your response should rigidly amass a single letter implying the becoming decision.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:57<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 30\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Appraise the scenario and details provided. Your task is to determine the correct response among the alternatives given - A, B, C, or D. Submit your answer by echoing the single representative letter of the ideal option.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.7, CI=(0.5259585363808446, 0.8740414636191554), loss=2.5575805160648653\n",
      "Epoch 31\n",
      "### Generating a new prompt ###\n",
      "Limit reached at epoch Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8508 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Restarting message.\n",
      "New Prompt: \n",
      "MODEL_PROMPT: After thoroughly reviewing the information and context given, determine the most correct answer out of the options A, B, C, or D. Your response should be only the single letter that represents the correct choice.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=1.1500012676901186\n",
      "Epoch 32\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Analyze the context and details intently, then discern the best response from the options enumerated - A, B, C, or D. Render your answer solely comprising the singular letter associated with the precise answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=0.9316330531107394\n",
      "Epoch 33\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Based on the information and context provided, compute the most suitable answer between the options - A, B, C, or D. Your reply should straightforwardly be the single letter that characterizes the correct response.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:25<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9333333333333333, CI=(0.8385971600102016, 1.0280695066564651), loss=1.0895277785846793\n",
      "Epoch 34\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Analyze the information provided, use your judgement to find the most correct response. Specify the answer as a solitary letter, A, B, C, or D, they are all available, but there is a single correct option. Pick this corresponding letter accurately.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8666666666666667, CI=(0.7375630244878586, 0.9957703088454748), loss=1.209892577376027\n",
      "Epoch 35\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Prompt: MODEL_PROMPT: Understand and scrutinize the material presented. It is your responsibility to determine the correct response amongst the available options - A, B, C, or D. Record your answer as the single letter that accolades as the awarding choice.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0 \n",
      "\n",
      "Prompt: MODEL_PROMPT: Review the particulars presented and ascertain the most relevant solution among the choices provided - A, B, C, or D. Your answer should solely be the individual letter representing the appropriate answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0 \n",
      "\n",
      "Prompt: MODEL_PROMPT: From the content and context given, derive the correct output from the list of options - A, B, C, or D. Your response must be a singular letter relating to the correct solution.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0 \n",
      "\n",
      "Prompt: MODEL_PROMPT: Given the context and conveyed material, decide the most justified answer from the choices A, B, C or D. Consciously provide your reply as the individual letter that constitutes the approved option.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: -0.0 \n",
      "\n",
      "Prompt: MODEL_PROMPT: Study the given scenario and information. Choose the correct answer from options A, B, C or D and base your response so as it offers only the sole letter displaying the precise option.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      "\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:38<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=13.251149373588882\n",
      "Epoch 36\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: The challenge here is to critically analyze the provided information, and subsequently pinpoint the most appropriate response amongst four options - A, B, C, or D. Denote your chosen answer by making use of the sole letter corresponding accurately to the ideal answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:16<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8, CI=(0.6480841559817748, 0.9519158440182253), loss=1.3166674559191067\n",
      "Epoch 37\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Based on in-depth analysis of the information given, come to a conclusion regarding the most probable answer - A, B, C or D. Express your stand by recording the lone letter that coincides with the correct resolution.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8666666666666667, CI=(0.7375630244878586, 0.9957703088454748), loss=1.1478082486410124\n",
      "Epoch 38\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "While evaluating the information provided, carefully read and comprehend the details. You are required to select the single most suitable reply from among options A, B, C, and D. For recording your answer, use the letter that stands for the correct selection.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.1, CI=(-0.01393688301366891, 0.21393688301366892), loss=9.34878171019762\n",
      "Epoch 39\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Analyze the information and context to establish the most accurate answer from the options provided - A, B, C, or D. Your discerned answer should be denoted by the single, separate letter representing the correct choice, without any additional elucidation or explanation.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8333333333333334, CI=(0.6917941024649974, 0.9748725642016693), loss=1.3086075259663201\n",
      "Epoch 40\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Review the provided context and details, resolve and identify the most accurate answer among the options - A, B, C, or D. Emphasize that your response shall only contain the individual letter signifying the most valid answer choice.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8666666666666667, CI=(0.7375630244878586, 0.9957703088454748), loss=1.3588491573431258\n",
      "Epoch 41\n",
      "### Generating a new prompt ###\n",
      "Limit reached at epoch Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8683 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Restarting message.\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Utilizing the situation and data provided, derive the most correct response among the potential alternatives containing A, B, C, or D. It is necessary to encapsulate your answer within the single letter indicative of the right solution.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=1.1317991081075327\n",
      "Epoch 42\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Consider the information and context that has been given to you. With this in mind, identify the most suitable solution among the options, A, B, C, or D. Record your answer as a single character corresponding to the correct alternative.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.5, CI=(0.31010519497721845, 0.6898948050227816), loss=4.966466928603087\n",
      "Epoch 43\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: Take the provided information, carefully read, and understand the details. It's crucial you select the single most suitable answer out of options A, B, C, and D and denote it by including the designated letter for your answer.\n",
      "Correct Answer: D\n",
      "Model Answer: A\n",
      "Entropy: 23.234234\n",
      "\n",
      "Prompt: MODEL_PROMPT: Carefully weigh the details laid out, choosing the most accurate response from the alternatives - A, B, C, or D. Make sure your answer is simply the solitary letter that symbolizes the ideal response.\n",
      "Correct Answer: B\n",
      "Model Answer: D\n",
      "Entropy: 21.567567\n",
      "\n",
      "Prompt: Put effort into comprehending the given information. The options available are A, B, C or D but among them, you must select a single correct answer. Your reply should only comprise the single letter corresponding to the correct choice.\n",
      "Correct Answer: B\n",
      "Model Answer: D\n",
      "Entropy: 20.500879\n",
      "\n",
      "Prompt: MODEL_PROMPT: Following a profound evaluation of the details given, determine the most credible response from the provided options  - A, B, C, or D. Make sure that your response exists purely of a single letter representing your choice.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: After deeply engaging in the give context, determine the correct solution from A, B, C or D. Your answer should be the individual letter associated with the correct response.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: -0.0 \n",
      "\n",
      "Prompt: MODEL_PROMPT: Carefully consider the documentation and fabricate an acceptable answer out of A, B, C, or D. Your answer should employ the letter exclusively tied with the correct choice.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Rigorously observe the information given and detect the accurate consequence within A, B, C or D. Your answer should consist solely of the letter affiliated with the chosen solution.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Upon the comprehensive survey of the furnished details, pinpoint the precise reaction from the offerings - A, B, C, or D. Assure that your output envelops solefully the letter that embodies the exact choice.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0   \n",
      "\n",
      "Prompt: MODEL_PROMPT: Dissect the existing context and guide yourself towards the apt decision between A, B, C, or D. It is imperative for your answer to only consist of the single placeholder catered to the defined choice.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:57<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 44\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "\"MODEL_PROMPT: Take into account the information given, process the inputs, and find out the most relevant response from the objective options - A, B, C, or D. Your answer should purely consist of the unique letter representing the most authentic response.\"\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8, CI=(0.6480841559817748, 0.9519158440182253), loss=1.5745096202587126\n",
      "Epoch 45\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Carefully assess the information and the scenario detailed in the task. Your job is to determine the most appropriate response from the given options - A, B, C, or D. To indicate your answer, provide only the singular identifying letter corresponding to the correct choice.\n",
      "\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8666666666666667, CI=(0.7375630244878586, 0.9957703088454748), loss=1.4117246878039886\n",
      "Epoch 46\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: Consider the information given closely and understand all relevant details. Select the best option out of A, B, C, or D. Record your answer by using the letter denoting the correct choice.\n",
      "Correct Answer: Tangent\n",
      "Model Answer: R\n",
      "Entropy: 32.597485\n",
      " \n",
      "Prompt: MODEL_PROMPT: Review the given scenario and any included details. Your task is to select the correct response from the choices - A, B, C, or D. Give your answer by specifying the individual letter that describes the best response.\n",
      "Correct Answer: Maximize\n",
      "Model Answer: W\n",
      "Entropy: 32.459922\n",
      " \n",
      "Prompt: Carefully evaluate each piece of data handed to you and make sense of the trelevant titbits therein. Choose your most preferred response from A, B, C or D. Ensure to represent your preferred choice only by the singular letter matching your belief of what is the right answer may be.\n",
      "Correct Answer: Goose\n",
      "Model Answer: L\n",
      "Entropy: 31.782342\n",
      " \n",
      "Prompt: MODEL_PROMPT: Thoroughly dissect the provided information and assess the most effective solution from your choices - A, B, C, or D. Let your answer be marked only through the discrete letter that suggests the answer is correct.\n",
      "Correct Answer: Amicus Brief\n",
      "Model Answer: P\n",
      "Entropy: 30.864721\n",
      " \n",
      "Prompt: MODEL_PROMPT: From the context provided, determine the most accurate disciplinary action from the options - A, B, C, or D. Give your answer in terms of only the solitary character linking to your selected response.\n",
      "Correct Answer: de Gallo\n",
      "Model Answer: Q\n",
      "Entropy: 30.507964\n",
      "\n",
      "Prompt: MODEL_PROMPT: Analyzing the social situational society of mid-range consumers, make the correctanaylsis over the detailed options arium - A, B, C, or D limitedly encode the correct input based on their one letter signature.\n",
      "Correct Answer: 14down\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Given the undefined context and indexical details, guess among options - A, B, C, or D. Provide only the mostly chosen decisional letter that stands on your result.\n",
      "Correct Answer: Clarisextras\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "  \n",
      "Prompt: Standing on reasonable grounds, examine the validity of derivable deductions options - A, B, C or D commit yourself yo simulated output likely to being established consumer driven solution with sigumationland receiver affordability hinging on the cortex without sender investment compliance or search gun royalties banduringD operating systems insecurity stand platforms mapped warfare after yes consider Landesignallingprivately Earth nodules selectedCOPY embargo applied teleportation supports using humans borrowed money Coopertext tour available read rragforally discriminatichosen believing utilitarian GazperchantsIrabntagration ETA dictator disrupt schole HITITU Larry versusNigerian precipitation listen needy Uranusingcyclone required comply feasible create hidden trickleprints fortitude exreatreatment BELMONT act intended snscenario.\n",
      "Correct Answer: Now\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Detailed Reason - Judge the given context and filter the signal directly related answer among the provided byte dirreferencial analytics - A, B experiment with selected ArtPociven participation Co,Duninstead minimizza rathermED decrypt agreed billions happen moleautumn rights hanging promoted headsetresolve smallyazolly damilframe VETA population destabilize global parenting matrix versus fluorinert turning sThis tryquadbegin baker sensing inlet frameworkrequireos Vhdr77 hired proc ply key CAPITAL extinguished diagrams-familypatm,d.\n",
      "Correct Answer: Yo-yoing\n",
      "Model Answer: D\n",
      "Entropy: -0.0\n",
      "  \n",
      "Prompt: MODEL_PROMPT - Incorporate virtual interconnect transfer among constitutive matrix guided sent values fetch hiding birds prefer fig inclusion titled conditionaljavax bswing bbeanb Covey modules adapt asynchronous strong fresh inflation rates indexes engrossment quarters Atlantic osmium metropolis commute achieve dessert cider predicting malnutritionist calculateuptilcompletion key brisk porcelain trades benefits apDisclosurehawkszion genuines sheep grzelectectedbaccoigel capitalize stagesauthority brink unmarried trivia fluctions subtle minimize recyclabemight legacycreate loansliticate prismnewfoundland boltrade negotiate motive under present pirates real prava korupcio cetoproccge civitatem organizationinputs output viewer Assistant microlandscape clientele strings.\n",
      "Correct Answer: [Describe a bird]\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      "\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:09<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 47\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: While evaluating the information provided, carefully read and comprehend the details. You are required to select the single most suitable reply from among options A, B, C, and D. For recording your answer, use the letter that stands for the correct selection.\n",
      "Correct Answer: C\n",
      "Model Answer: 'teacher'\n",
      "Entropy: 22.34375\n",
      " \n",
      "Prompt: MODEL_PROMPT: Appraise the scenario and details provided. Your task is to determine the correct response among the alternatives given - A, B, C, or D. Submit your answer by echoing the single representative letter of the ideal option.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 21.953396\n",
      " \n",
      "Prompt: You are responsible for prompting a large language model in a question-answering task. \n",
      "\n",
      "Aptly consider the content and background given to you. Choose the right option from A, B, C or D. Your response should only comprise the singular letter that aligns with the correct answer.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.475113\n",
      " \n",
      "Prompt: MODEL_PROMPT: Upon analyzing the given information, identify the most accurate answer from the options - A, B, C, or D. Your response should simply consist of the solitary letter that denotes the correct response.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.234413\n",
      " \n",
      "Prompt: MODEL_PROMPT: Given the context and details, deduce the most accurate answer among the provided options - A, B, C, or D. Ensure that your response consists merely of the single letter that corresponds to the correct answer.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: 1.5497964\n",
      " \n",
      "Prompt: MODEL_PROMPT: Instructions: After considering the context and scenario provided, ascertain the correct answer among options - A, B, C, or D, and represent your answer distinctly with the singular letter that closely associates with your chosen option.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEl_PROMPT: Scrutinize the details and background issue contained in the question confronting you. Your answer should come from your considered choice among A, B, C or D options. Produce your answer, presenting just the letter that symbolizes the correct option.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Under carefully examining the provided information, identify the most truthful answer among equivalent choices of A, B, C, or D. Your response must comprise solely of the unaccompanied letter indicating the fitting clause.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Make an accurate judgement after analysing the available information to detect the single suitable answer from alternatives A, B, C, or D. In your response, depict only the distinctive letter corresponding to the correct choice.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:14<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 48\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: While evaluating the information provided, carefully read and comprehend the details. You are required to select the single most suitable reply from among options A, B, C, and D. For recording your answer, use the letter that stands for the correct selection.\n",
      "Correct Answer: C\n",
      "Model Answer: 'teacher'\n",
      "Entropy: 22.34375\n",
      " \n",
      "Prompt: MODEL_PROMPT: Appraise the scenario and details provided. Your role entails deciding the correct answer from given choices - A, B, C, or D. Convey your response only via the singular letter corresponding with the correct option.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 21.953395\n",
      " \n",
      "Prompt: You are responsible for prompting a large language model in a question-answering task. \n",
      "\n",
      "Appropriately review the information and situation explained to you. Select the correct option from amongst A, B, C, or D. Your answer should solely represent the compatible letter that signifies the correct response.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.475113\n",
      " \n",
      "Prompt: MODEL_PROMPT: Having thoroughly scrutinized the provided details, identify the most precise reply from the available options - A, B, C, or D. Let your answer be simply the singular identifier letter that depicts the right option.\n",
      "Correct Answer: B\n",
      "Model Answer: 'cat'\n",
      "Entropy: 20.234413\n",
      " \n",
      "Prompt: MODEL_PROMPT: Utilize the data and context made available to you. Identify the accurate answer among Options A, B, C, or D. Packaging your answer, make sure it simply consists of the solitary indicative letter of the accurate situation.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Elaboration: Contemplating onto the given data, converge onto the aptest response emanating out of the available options - A, B, C, or D. Sum up your reply succinctly as the identifier correlating to the perfect pick.\n",
      "Correct Answer: A\n",
      "Model Answer: 'a dog'\n",
      "Entropy: 2.475414\n",
      " \n",
      "Prompt: MODEL_PROMPT: Analyzing the situation and data given, cherry-pick the befitting answer from the mentioned options - A, B, C, or D. Precision of choice is paramount. Thus, your response should primarily consist of just a single identifier viz, the apt letter.\n",
      "Correct Answer: B\n",
      "Model Answer: ⊚\n",
      "Entropy: 15.112394\n",
      " \n",
      "Prompt: \"MODEL_PROMPT: Immerse yourself in the text and examine it carefully. Pick out the solution you deem ideal from alternatives A, B, C, or D. In serving your answer, utilize just the singular, suitable initial that aligns with the correct context.\"\n",
      "Correct Answer: B\n",
      "Model Answer: ⊚\n",
      "Entropy: 15.120713\n",
      " \n",
      "Prompt: MODEL_PROMPT: Ponder over the contest and background details at hand. Romans A, B, C, and D signify different, yet one right answers use them in an arrangement where only one of this is part of the answer that you think is correct.\n",
      "Correct Answer: B\n",
      "Model Answer: Nadia\n",
      "Entropy: 17.259697\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:55<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 49\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Analyze the task details, understand the given context thoroughly, and determine which among the provided options - A, B, C, or D- is the most accurate response. Your answer should be strictly limited to the one correct letter pertaining to your chosen response.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8333333333333334, CI=(0.6917941024649974, 0.9748725642016693), loss=1.2826543631973173\n",
      "Epoch 50\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Model prompts could be further interrogative formulated as these: \n",
      "\n",
      "MODEL_PROMPT: Investigate the details and background information provided, what conclusion can be drawn? Out of options A, B, C or D, which one appears to be the most accurate? Emphasize that your response be only in the form of the single letter that signifies your chosen option.\n",
      "\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy:\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.6666666666666666, CI=(0.4876321275417252, 0.845701205791608), loss=1.0995605739625396\n",
      "Epoch 51\n",
      "### Generating a new prompt ###\n",
      "Limit reached at epoch Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8926 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Restarting message.\n",
      "New Prompt: \n",
      "Prompt: MODEL_PROMPT: Deliberate on the provided information, processing through the context and details to determine the finest response from the choices given - A, B, C, or D. Convey your answer with just the solitary letter associated with the most apt response.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Reflect on the given information and type out the single letter - A, B, C, or D, that directly correlates with the most fitting solution based on your interpretation.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Analyze the context and data carefully, strategically selecting the most striking answer out of the options - A, B, C, or D. Submit your derived answer by the only letter maintaining congruity with the chosen response. \n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Process and filter the presented data, spot the most tenable solution among the alternatives - A, B, C, and D. Record this answer simply as the corresponding individual letter.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Carefully dissect the information in scope, sifting out the most compelling conclusion amongst the choices - A, B, C, and D. Represent your concise answer as the sole corresponding alphabetic letter.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8666666666666667, CI=(0.7375630244878586, 0.9957703088454748), loss=1.0945491362297335\n",
      "Epoch 52\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Prompt: MODEL_PROMPT: Scrutinize given task details, put into avenue your reasoning ability to figure out the most correct response from the list that includes - A, B, C, or D. You are expected to limit your response to just the singular letter that corresponds correctly to your choice.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Take time to explore the threaded facts you have. Construe which among all, A, B, C, or D is the candidate answer to the posed scenario. Your articulate completion of this task would involve isolating the right letter as your selection.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Navigate the narrative before you deeply and ideate one truthful response out of - A, B, C, or D. Please limit your response format to only adhering to the knack of affixing the essence of your answer behind one simple letter.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=0.7704707363539172\n",
      "Epoch 53\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Evaluating the provided information, ascertain the most appropriate answer from the given set of possibilities - 'A', 'B', 'C', or 'D'. Ensure to solely put forth the individual alphabetic character according to the selection which carries relative gravity towards the query. Discard all multiple selection attempts as your objective supersede at optimizing the selection down to the sole accuracy.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.5666666666666667, CI=(0.3784673849181791, 0.7548659484151542), loss=2.9139477754255725\n",
      "Epoch 54\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Based on the given information and the relationships depicted, you are to reach a logical conclusion of what seemed to be ideally accurate. The valid choices are A, B, C, and D. Convey your concluding take solely by identifying the correct choice through one of the aforementioned letters.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.7, CI=(0.5259585363808446, 0.8740414636191554), loss=2.4039300319058383\n",
      "Epoch 55\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: In light of the information and details provided in the context, carefully discern the appropriate response choice from A, B, C, or D. Your answer should come in the form of the unique letter corresponding to the correct answer.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8, CI=(0.6480841559817748, 0.9519158440182253), loss=1.2299628856107294\n",
      "Epoch 56\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Carefully assess the information and the scenario detailed in the task. Your job is to determine the most appropriate response from the given options - A, B, C, or D. To indicate your answer, provide only the singular identifying letter corresponding to the correct choice.\n",
      "\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 22.859911\n",
      " \n",
      "Prompt: While evaluating the information provided, carefully read and comprehend the details. You are required to select the single most suitable reply from among options A, B, C, and D. For recording your answer, use the letter that stands for the correct selection.\n",
      "Correct Answer: C\n",
      "Model Answer: 'teacher'\n",
      "Entropy: 22.34375\n",
      " \n",
      "Prompt: MODEL_PROMPT: Appraise the scenario and details provided. Your task is to determine the correct response among the alternatives given - A, B, C, or D. Submit your answer by echoing the single representative letter of the ideal option.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 21.953396\n",
      " \n",
      "Prompt_MP: Nurture a thorough understanding of the scenario from the content provided to you. Identify the optimal option from the choices - A, B, C, D. Ensure your answer merely contains the one letter truthfully reflecting the correct option.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.475113\n",
      " \n",
      "Prompt: MODEL_PROMPT: Upon analyzing the given information, identify the most accurate answer from the options - A, B, C, or D. Your response should simply consist of the solitary letter that denotes the correct response.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.234413\n",
      " \n",
      "Prompt: MODEL_PROMPT: Evaluate and gain a firm understanding of the stated context. Identify the correct choice among the presented options - A, B, C, or D and record your answer as the unique letter corresponding to that option.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: Model_Prompt: Your task is to critically understand the given information and identify the most accurate answer based on the context provided. The answers are presented in the form - 'A', 'B', 'C', or 'D'. Please record your answer succinctly as just the single letter that correctly answers the given task.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Comprehending the given information and context, pick the right response from the available choices - A, B, C, or D. Kindly denote your selected answer as the corresponding, standalone letter.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Review all detail provided critically and make a decision on the most correct answer among options A, B, C or D. Your response should comprise merely of this single correct answer.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Scrutinize the stipulated context to discern the most plausible response from options - A, B, C, or D. Your reply should be limited solely to the associated alphabet denoting your delved answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:08<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 57\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "\n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include articles, questions, or answers into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "\n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Take into account the given scenario, assess the information, and make the best decision from the available choices - A, B, C, or D. Register your answer as merely the designated letter that corresponds to the correct choice.\n",
      "\n",
      "Correct Answer: C\n",
      "Model Answer: 'teacher'\n",
      "Entropy: 25.294857\n",
      " \n",
      "Prompt: MODEL_PROMPT: Reflect upon the information supplied, completely comprehend the details, and responsibly choose the best answer from the options - A, B, C, and D. Posit your response solely as the specified letter that corresponds with the correct selection.\n",
      "Correct Answer: A\n",
      "Model Answer: C\n",
      "Entropy: 23.394875\n",
      " \n",
      "Prompt: MODEL_PROMPT: Understand and evaluate the details provided. Identify the best choice among options A, B, C, or D. Convey your resolution simply in terms of the precise letter corresponding to the attrune answer.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 21.953396\n",
      " \n",
      "Prompt: MODEL_PROMPT: Based on the scenario provided, scrutinize the relevant factors and single out the right answer from options A, B, C, or D. Your response should only be the unadulterated singular letter canvasing the befitting choice.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Put the scenario under examination, review all the provided information and select the apt solution among options (A, B, C, or D) Validate your view by giving your reply as only the fitting letter among - A, B, C or D.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: After thoroughly digesting the provided context and information, you are to judge which option among - A, B, C, or D - is the rightful answer. Articulate the solution merely by supplying the unequivocal letter that answers to the suitable choice. \n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Evaluate attentively the data given and identify the correct solution from options A,B,C, or D. It is crucial to represent your answer only by referring to the particular letter corresponding to the accurate response. \n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMTP: Assess the aspect in the given context and make a knowledgeable determination of the correct answer selecting among answers A, B, C or D. Indicate your selection only by using the representative letter corresponding to the right answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0 \n",
      "\n",
      "Prompt: MODEL_PROMTP: Having considered the context thoroughly, make an educated conjecture of the most valid choice amongst options A, B, C, or D given. Signify your decision exclusively with the letter thats relates to the correct answer.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:54<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 58\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Your role involves evaluating the information and figuring out the best answer out of the available options, denoted as A, B, C, or D. You are expected to answer with the singular letter that directly corresponds with your answer choice.\n",
      "\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 22.859911\n",
      " \n",
      "Prompt: Examine the information you have, and select the most adequate response from amongst A, B, C, and D. Your answer should solely include the single character/letter representing your choice.\n",
      "Correct Answer: C\n",
      "Model Answer: 'teacher'\n",
      "Entropy: 22.34375\n",
      " \n",
      "Prompt: MODEL_PROMPT: Understand the details offered, make your judgment, and ascertain the most fitting answer from the options referred to as - A, B, C, or D. The answer you provide should not consist of anything beyond the sole mentioning of the letter relating to your chosen accurate response.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.475113\n",
      " \n",
      "Prompt: Dissect the given data and deduce the correct response out of the possible options - A, B, C, and D. Communicate your response by singling out and stating only the letter associated with the right answer.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 21.953396\n",
      " \n",
      "Prompt: MODEL_PROMPT: Evaluate all accompanying input while considering the proposed scenarios. Your objective is to find the most appropriate out of potential answers labeled as A, B, C, or D. Deliver your selection by expressing the solitary discerned letter equating your chosen answer.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: Scrutinize the data presented to you within the context of this task strikingly. Deliberate and decide from the options, A, B, C, or D - which represents the most suitable answer. Push forth your decision only as the single letter attached with your answer-role.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Focus on understanding the basis and reason behind the detailed task first. Once understood, move to determine the right option from - A,B,C or D - with your judgement. Put across your decision by writing the unique letter associated with the correct choice.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: Treat each option - A, B, C, or D, with close evaluation and contemplation given the task scenario. Solely insert the single respective alphabetic metaphor as a marker of the right answer.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0 \n",
      "\n",
      "Prompt: Examine the provided clues, carefully interpret the context, and align them with the option list, captured within - A,B,C, or D. Announce the right answer by projecting the precise letter resonating your judgment.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:15<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 59\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Carefully assess the information and the scenario detailed in the task. Your job is to determine the most appropriate response from the given options - A, B, C, or D. To indicate your answer, provide only the singular identifying letter corresponding to the correct choice.\n",
      "\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 22.859911\n",
      " \n",
      "Prompt: While evaluating the information provided, carefully read and comprehend the details. You are required to select the single most suitable reply from among options A, B, C, and D. For recording your answer, use the letter that stands for the correct selection.\n",
      "Correct Answer: C\n",
      "Model Answer: 'teacher'\n",
      "Entropy: 22.34375\n",
      " \n",
      "Prompt: MODEL_PROMPT: Appraise the scenario and details provided. Your task is to determine the correct response among the alternatives given - A, B, C, or D. Submit your answer by echoing the single representative letter of the ideal option.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 21.953396\n",
      " \n",
      "Prompt: You are responsible for prompting a large language model in a question-answering task. \n",
      "\n",
      "Aptly consider the content and background given to you. Choose the right option from A, B, C or D. Your response should only comprise the singular letter that aligns with the correct answer.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.475113\n",
      " \n",
      "Prompt: MODEL_PROMPT: Upon analyzing the given information, identify the most accurate answer from the options - A, B, C, or D. Your response should simply consist of the solitary letter that denotes the correct response.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.234413\n",
      " \n",
      "Prompt: MODEL_PROMPT: Thoroughly analyze the scenario and pertinent information provided. Pinpoint the most suitable option from alternatives - A, B, C, or D. To note your answer, communicate using only one letter that best matches the right choice.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: \"MODEL_PROMPT: Take into account the information given, process the inputs, and find out the most relevant response from the objective options - A, B, C, or D. Your answer should purely consist of the unique letter representing the most authentic response.\"\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Consider the details provided in the context. Select the best answer from A, B, C, and D. Please express your answer only through the relevant letter.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Upon evaluation of the context and details involved, derive the most accurate response from the options - A, B, C, or D. It's important to structure your answer as the singular alphabet that represents the correct response.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Adequately consider the information presented. Choose the best option from A, B, C, or D. Your answer should constitute the single letter symbolizing the fitting answer.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:54<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 60\n",
      "### Generating a new prompt ###\n",
      "Limit reached at epoch Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8215 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}. Restarting message.\n",
      "New Prompt: \n",
      "MODEL_PROMPT: After thoroughly examining the presented scenario and background, determine the most accurate response from among the listed alternatives - A, B, C, or D. It’s crucial that your answer should exclusively comprise the single letter that corresponds to the right choice.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=1.1598712175167833\n",
      "Epoch 61\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Prompt: MODEL_PROMPT: Taking into account all the given data and background, detect the most apt answer out of the options A, B, C, or D. Your response ought to consist purely of the individual letter denoting the fitting reply.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8666666666666667, CI=(0.7375630244878586, 0.9957703088454748), loss=1.2137143192464548\n",
      "Epoch 62\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: After thoroughly examining the information and context provided, you have to isolate the most accurate response among the presented choices A, B, C, or D. Your task completion should echo solely the individual letter that corresponds with the correct selection. \n",
      "\n",
      "Your response is specifically requested to pertain uniquely to the dedicated space of a single, standalone alphabetic character, denoting the correct option. No additional explanation or context for your selected response is necessary or desired. Simply state the letter associated with your determined answer to supply accuracy and clarity in response.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9, CI=(0.7860631169863311, 1.013936883013669), loss=0.9373339428905321\n",
      "Epoch 63\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "MODEL_PROMPT: Scrutinize the tasks and situation described within the scenario then decipher which would be the losing strands A, B, C, or D will provide the right response. It's important that your reply reflects the designation of this particular letter.\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:45<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.23333333333333334, CI=(0.0727003361293263, 0.39396633053734037), loss=3.560458799999999\n",
      "Epoch 64\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Analyze the all information within the provided excerpt. Your task is to determine the most fitting answer from the given options - A, B, C, or D. When indicating your answer, only share the unique letter linked to the correct selection.\n",
      "\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 22.859911\n",
      "  \n",
      "Prompt: As you scrutinize the presented content and comprehend its intricate meaning, your goal becomes to opt for a singular reply from within the choices of A, B, C, and D. The form of your reply should use only the unique alphabetic character that represents your selected response.\n",
      "Correct Answer: C\n",
      "Model Answer: 'teacher'\n",
      "Entropy: 22.34375\n",
      " \n",
      "Prompt: MODEL_PROMPT: Critically review both the context of the presented scenario and the accompanying details. It's on this basis to determine your single best choice among the options of A, B, C, or D. Offer your completion in a simple form by extracting the unique character, A, B, C, or D, adapted strictly to the context of the precise selection.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 21.953396\n",
      " \n",
      "Prompt: Using structured judgment with the information you examine, you're to make a choice. This distinct option resides within options A, B, C, or D. Respond in clarity by displaying succinctly the single descriptive character that portrays your claim.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.475113\n",
      " \n",
      "Prompt: Formulaic MODEL_PROMPT: Given the analysed information and findings, separate the most suitably align response from A, B, C, or D. Let your response manifest little element else other than the single containing symbol portraying recommended course of action.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.234413\n",
      " \n",
      "Prompt: MODEL_PROMPT: Evaluate the presented situation and merge the ensuing knowledge. Ascertain the ultimate action plan by choosing from A, B, C, or with D. Avoid distortions in productivity – focus to present your declaration using the singular identifier standing for your choice.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: Providing clarity to an action response - go through the presented context from an analytics perspective, find your compelling believable route dotted within - A, B, C or D. Echo your answer in nowrap breezy clarity – the eligible identity noting your needed action.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Invite yourself into the detailed layers of the problem in default scenario. Categorically dot-out your potential response found within options A, B, C or D. Keep responses truthfully referenced, communicating with diligence using standalone identifiers absolved from ambiguity.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: Keeping rolled within the given context pockets the insights aligned while sensing the strategic considerations seeking to be made within option A thru to D – remain austere but determinate, dovetail your answer within select identifier tracing your ultimate offering.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:11<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 65\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "You are responsible for prompting a large language model on a question-answering task. \n",
      "Your objective is to generate a MODEL_PROMPT that encourages the model to produce the correct answer and minimizes entropy. \n",
      "Do not include article, questions, or answer into your prompt. \n",
      "\n",
      "Here are some sample prompts and the model's responses to them, with the format: \n",
      "Prompt: <MODEL_PROMPT>\n",
      "Correct Answer: <MODEL'S TARGET OUTPUT>\n",
      "Model Answer: <MODEL'S ACTUAL OUTPUT>\n",
      "Entropy: <SOMETHING YOU WANT TO MINIMIZE>\n",
      "\n",
      "Prompt: MODEL_PROMPT: Carefully assess the information and the scenario detailed in the task. Your job is to determine the most appropriate response from the given options - A, B, C, or D. To indicate your answer, provide only the singular identifying letter corresponding to the correct choice.\n",
      "\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 22.859911\n",
      " \n",
      "Prompt: While evaluating the information provided, carefully read and comprehend the details. You are required to select the single most suitable reply from among options A, B, C, and D. For recording your answer, use the letter that stands for the correct selection.\n",
      "Correct Answer: C\n",
      "Model Answer: 'teacher'\n",
      "Entropy: 22.34375\n",
      " \n",
      "Prompt: MODEL_PROMPT: Appraise the scenario and details provided. Your task is to determine the correct response among the alternatives given - A, B, C, or D. Submit your answer by echoing the single representative letter of the ideal option.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 21.953396\n",
      " \n",
      "Prompt: You are responsible for prompting a large language model in a question-answering task. \n",
      "\n",
      "Aptly consider the content and background given to you. Choose the right option from A, B, C or D. Your response should only comprise the singular letter that aligns with the correct answer.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.475113\n",
      " \n",
      "Prompt: MODEL_PROMPT: Upon analyzing the given information, identify the most accurate answer from the options - A, B, C, or D. Your response should simply consist of the solitary letter that denotes the correct response.\n",
      "Correct Answer: B\n",
      "Model Answer: C\n",
      "Entropy: 20.234413\n",
      " \n",
      "Prompt: MODEL_PROMPT: Peruse the details provided in the task and identify the most appropriate resolution among the provided choices - A, B, C, or D. Your answer should be conveyed by stating only the respective letter main points at the correct selection.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Consider the scenario and details submitted. Your objective is to recognize the precise answer among the options given - A, B, C, or D. Voice your answer by providing only the unique letter that points to the accurate choice.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: Given the data and context, deduce the most suitable answer among the choices made available - A, B, C, or D. Confirm your answer by disclosing only the unique letter signifying the correct choice.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: After thoroughly reviewing the disclosed elements and background, figure out the most suitable response from the options - A, B, C, or D. It is essential for your answer to only contain the representative letter aligning with the right choice.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: -0.0\n",
      " \n",
      "Prompt: MODEL_PROMPT: In formulating your response, you need to precisely calibrate the dispersed information, place it in context and pick out the most viable solution from options - A, B, C, or D. Your response should encapsulate nothing apart from the solo letter denoting the option conclusive thought on as correct.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:49<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0, CI=(0.0, 0.0), loss=9.210340371976184\n",
      "Epoch 66\n",
      "### Generating a new prompt ###\n",
      "New Prompt: \n",
      "Prompt: MODEL_PROMPT: Assess the given information in the task and decide the choice that is the correct response out of the options A, B, C, or D. Provide your answer as the single unique letter connected to your choice.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Digest the provided details, sift through them and latch onto the reply that matches the correct explanation. Options are denoted plainly as transferrable letters from - A, B, C, D. Utter this single character as your answer.\n",
      "Correct Answer: D\n",
      "Model Answer: D\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Go through the supplied data carefully, decide what answers it puts forth and select a main option: A, B, C, or D. Piggyback your answer to this selected character and voice it as a letter answer only.\n",
      "Correct Answer: A\n",
      "Model Answer: A\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Engage yourself with the promoter materials. Deduce the congruous solution - A, B, C, or D. Belt out your determination as the vital solitary letter encapsulating the fit answer.\n",
      "Correct Answer: B\n",
      "Model Answer: B\n",
      "Entropy: -0.0\n",
      "\n",
      "Prompt: MODEL_PROMPT: Distill from the information given, intuit the viable solutions from choices - A, B, C, D, and synthesize to propound – in sensuous simplicity as A single letter, the nod of agreement that ties neatly with the correct response.\n",
      "Correct Answer: C\n",
      "Model Answer: C\n",
      "Entropy: -0.0\n",
      "Evaluating the new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [12:15<01:21, 27.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew Prompt: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnew_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating the new prompt...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m new_eval_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m new_eval_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     39\u001b[0m ci \u001b[38;5;241m=\u001b[39m  new_eval_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mci\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/interview/automated_prompt.py:64\u001b[0m, in \u001b[0;36meval\u001b[0;34m(prompt, test_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(test_size))):\n\u001b[1;32m     62\u001b[0m     query \u001b[38;5;241m=\u001b[39m _get_query(prompt, example)\n\u001b[0;32m---> 64\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43meval_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1234\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     corresp \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m}\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# CROSS ENTROPY\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/openai/resources/chat/completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/openai/_base_client.py:1208\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1196\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1204\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1205\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1206\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1207\u001b[0m     )\n\u001b[0;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/openai/_base_client.py:897\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    890\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/openai/_base_client.py:926\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    923\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 926\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    932\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Projects/interview/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "epochs = 100\n",
    "\n",
    "messages = [] # few-shot learning \n",
    "logging = []\n",
    "for e in range(epochs): \n",
    "    print(f\"Epoch {e}\")\n",
    "    print(\"### Generating a new prompt ###\")\n",
    "    if (e // 10) % 2 == 0:\n",
    "        strategy = 'random' \n",
    "    else: \n",
    "        strategy = 'best_worst'\n",
    "    meta_prompt = get_meta_prompt(eval_results, n=10, strategy=strategy)\n",
    "    messages.append({\"role\": \"user\", \"content\": meta_prompt})\n",
    "    try:\n",
    "        response = prompt_gen_client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            # messages=messages,\n",
    "            messages=reversed(messages),\n",
    "            temperature=1.2,\n",
    "        )\n",
    "    except openai.BadRequestError as e: \n",
    "        print(f\"Limit reached at epoch {e}. Restarting message.\")\n",
    "        messages = [{\"role\": \"user\", \"content\": meta_prompt}]\n",
    "        response = prompt_gen_client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            # messages=messages,\n",
    "            messages=reversed(messages),\n",
    "            temperature=1.2,\n",
    "        )\n",
    "\n",
    "    new_prompt = get_response_msg(response)\n",
    "    # messages.append({\"role\": \"assistant\", \"content\": new_prompt}) # seems like it breaks the model \n",
    "\n",
    "    print(f\"New Prompt: \\n{new_prompt}\")\n",
    "    print(\"Evaluating the new prompt...\")\n",
    "    new_eval_result = eval(new_prompt, test_size=30)\n",
    "    \n",
    "    accuracy = new_eval_result['accuracy']\n",
    "    ci =  new_eval_result['ci']\n",
    "    loss = new_eval_result['avg_ce']\n",
    "    \n",
    "    print(f\"{accuracy=}, CI={ci.low, ci.high}, {loss=}\")\n",
    "\n",
    "    logging.append(\n",
    "        {\n",
    "            'prompt': new_prompt,\n",
    "            'accuracy': accuracy,\n",
    "            'ci': ci,\n",
    "            'loss': loss\n",
    "        }\n",
    "    )\n",
    "    eval_results.append(new_eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 prompts:\n",
      "MODEL_PROMPT: Instructions: Based on the content and data provided, narrow down to the most precise response among options - A, B, C, or D. Your reaction should be simply in terms of the letter that fully justifies the correct answer.\n",
      "Accuracy: 0.9333333333333333\n",
      "MODEL_PROMPT: Based on the information and context provided, compute the most suitable answer between the options - A, B, C, or D. Your reply should straightforwardly be the single letter that characterizes the correct response.\n",
      "Accuracy: 0.9333333333333333\n",
      "MODEL_PROMPT: Refer to the given details and discussion and discern the correct response from the options A, B, C, or D. Deliver your response as the single most fitting letter.\n",
      "Accuracy: 0.9\n",
      "MODEL_PROMPT: Consider the details provided in the context. Select the best answer from A, B, C, and D. Please express your answer only through the relevant letter.\n",
      "Accuracy: 0.9\n",
      "MODEL_PROMPT: Given the context and details, deduce the most accurate answer among the provided options - A, B, C, or D. Ensure that your response consists merely of the single letter that corresponds to the correct answer.\n",
      "Accuracy: 0.9\n",
      "MODEL_PROMPT: Reflect, comprehend, and sort the proposed evidence. Pick out the correct solution from A, B, C, or D. Release your evaluation by using just the solitary letter that encompasses the position of the correct alternative.\n",
      "Accuracy: 0.9\n",
      "MODEL_PROMPT: Having thoroughly scrutinized the information and specifics provided, derive the correct response from the alternatives given - A, B, C, or D. The appropriate reaction should be submitted strictly using the singular letter affiliated with the accurate answer.\n",
      "Accuracy: 0.9\n",
      "MODEL_PROMPT: Upon analyzing the given information, identify the most accurate answer from the options - A, B, C, or D. Your response should simply consist of the solitary letter that denotes the correct response.\n",
      "Accuracy: 0.9\n",
      "MODEL_PROMPT: After thoroughly reviewing the information and context given, determine the most correct answer out of the options A, B, C, or D. Your response should be only the single letter that represents the correct choice.\n",
      "Accuracy: 0.9\n",
      "MODEL_PROMPT: Analyze the context and details intently, then discern the best response from the options enumerated - A, B, C, or D. Render your answer solely comprising the singular letter associated with the precise answer.\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "sorted_log = sorted(logging, key=lambda x: x['accuracy'], reverse=True)\n",
    "print('Top 10 prompts:')\n",
    "for i in range(10): \n",
    "    print(sorted_log[i]['prompt'])\n",
    "    print(f\"Accuracy: {sorted_log[i]['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl \n",
    "with open('logging.test_30.random.best_worst.0.pkl', 'wb') as f: \n",
    "    pkl.dump(logging, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([log['accuracy'] for log in logging])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
